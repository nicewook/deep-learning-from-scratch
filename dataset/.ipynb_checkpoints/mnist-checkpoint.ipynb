{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist.py 파일을 분석해본다\n",
    "\n",
    "- mnist 파일을 인터넷에서 가져와서 train, test 등으로 분류해주는 함수가 구현되어 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-90b6cf169aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdataset_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 현재 파일의 절대위치를 dataset_dir이라 한다\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0msave_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/mnist.pkl\"\u001b[0m  \u001b[1;31m# 현재 파일 위치에 나중에 파일 저장할 것. mnist.pkl 이라는 이름으로\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "# urllib.request 라는 Python 3.x 파일을 사용\n",
    "try:\n",
    "    import urllib.request\n",
    "except ImportError:\n",
    "    raise ImportError('You should use Python 3.x')\n",
    "import os.path\n",
    "import gzip  # 압축풀기\n",
    "import pickle  # 파일 읽고 쓰기\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# urllib.request라는 함수를 통해서 아래 위치의 압축파일들을 가져올 예정\n",
    "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
    "key_file = {\n",
    "    'train_img':'train-images-idx3-ubyte.gz',\n",
    "    'train_label':'train-labels-idx1-ubyte.gz',\n",
    "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
    "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
    "}\n",
    "\n",
    "dataset_dir = os.path.dirname(os.path.abspath(__file__))  # 현재 파일의 절대위치를 dataset_dir이라 한다\n",
    "save_file = dataset_dir + \"/mnist.pkl\"  # 현재 파일 위치에 나중에 파일 저장할 것. mnist.pkl 이라는 이름으로 \n",
    "\n",
    "train_num = 60000\n",
    "test_num = 10000\n",
    "img_dim = (1, 28, 28)  # 이미지는 1채널, 28x28 이미지이다\n",
    "img_size = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def _download(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "    \n",
    "    if os.path.exists(file_path):  # 이미 다운로드 받았으면 바로 리턴할 것\n",
    "        return\n",
    "\n",
    "    print(\"Downloading \" + file_name + \" ... \")\n",
    "    urllib.request.urlretrieve(url_base + file_name, file_path)  # 처음 다운로드 하는 것이라면 urllib.request를 사용해서 가져온다\n",
    "    print(\"Done\")\n",
    "    \n",
    "def download_mnist():\n",
    "    \"\"\"\n",
    "    key_file에는 파일 이름들이 이미 저장되어 있다.\n",
    "    이걸 하나씩 _download() 함수를 통해 순차적으로 가져오는 것이다. \n",
    "    \"\"\"\n",
    "    for v in key_file.values():\n",
    "       _download(v)\n",
    "        \n",
    "def _load_label(file_name):\n",
    "    \"\"\"\n",
    "    다운로드 받은 특정 파일 하나를 \n",
    "    1) gzip으로 푼 다음에 \n",
    "    2) label을 읽는다. - np.frombuffer() 사용\n",
    "    \"\"\"\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "    \n",
    "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "            # https://docs.scipy.org/doc/numpy/reference/generated/numpy.frombuffer.html\n",
    "            # 아래는 8번 부터 np.uint8 type 형태로 가져오라는 것\n",
    "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def _load_img(file_name):\n",
    "    \"\"\"\n",
    "    위에는 offset 8부터지만 이번에는 16부터 가져오라는 것\n",
    "    위에는 라벨이고 이건 image 이다\n",
    "    \"\"\"\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "    \n",
    "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "            \n",
    "    # reshape하라는 것인데, 전체를 img_size로 reshape 하라는 것인가 봄\n",
    "    data = data.reshape(-1, img_size)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    return data\n",
    "    \n",
    "def _convert_numpy():\n",
    "    # 다운로드 받은 파일들을 nupmy 배열로 바꿔서 저장해줌\n",
    "    dataset = {}\n",
    "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
    "    dataset['train_label'] = _load_label(key_file['train_label'])    \n",
    "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
    "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def init_mnist():\n",
    "    # 초기화 작업\n",
    "    download_mnist()  # 전부 다운로드 받은 다음에 \n",
    "    dataset = _convert_numpy()  # numpy 배열로 바꾼다. \n",
    "    print(\"Creating pickle file ...\") # 이것을 일단 pickle 파일로 바꿔둔다. \n",
    "    with open(save_file, 'wb') as f:  # pickle 파일을 열어둔 다음에 dataset 딕셔너리를 통째로 pickle로 저장해둔다\n",
    "        pickle.dump(dataset, f, -1)\n",
    "    print(\"Done!\")\n",
    "\n",
    "def _change_ont_hot_label(X):\n",
    "    \"\"\"\n",
    "    1) 그냥 라벨은 1,2 처럼 해당 이미지의 정답 index를 가지고 있다.\n",
    "    2) one-hot-label은 이를 리스트로 가지고 있다. \n",
    "        - 0에서 9중에서 0 이라면 [1,0,0,0,0,0,0,0,0,0] 이런식이다. \n",
    "    \"\"\"\n",
    "    T = np.zeros((X.size, 10))  # 따라서 총 라벨 갯수 * 10 형태로 만든 다음에 \n",
    "    for idx, row in enumerate(T): \n",
    "        row[X[idx]] = 1  # 각 행의 X[idx] 를 1로 만들어준다\n",
    "        \n",
    "    return T\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이게 실제 동작함수이다 \n",
    "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
    "    \"\"\"MNIST 데이터셋 읽기\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    normalize : 이미지의 픽셀 값을 0.0~1.0 사이의 값으로 정규화할지 정한다.\n",
    "    one_hot_label : \n",
    "        one_hot_label이 True면、레이블을 원-핫(one-hot) 배열로 돌려준다.\n",
    "        one-hot 배열은 예를 들어 [0,0,1,0,0,0,0,0,0,0]처럼 한 원소만 1인 배열이다.\n",
    "    flatten : 입력 이미지를 1차원 배열로 만들지를 정한다. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블)\n",
    "    \"\"\"\n",
    "    \n",
    "    # pickel 파일이 없으면 만들어존다 \n",
    "    if not os.path.exists(save_file):\n",
    "        init_mnist()\n",
    "        \n",
    "    # 만들든, 만들어져 있든, pickel 파일을 읽어와서 다시 dataset 딕셔너리로 풀어준다. \n",
    "    with open(save_file, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    \n",
    "    # 각각의 픽셀은 0-255 값을 가진다. \n",
    "    # 이걸 255로 나누면 0-1 안의 normalized 된 값이 된다 \n",
    "    if normalize:\n",
    "        for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].astype(np.float32)  # 원래는 0-255의 정수였는데 이를 소수점을 쓰는 실수로 바꾸어준다\n",
    "            dataset[key] /= 255.0\n",
    "            \n",
    "    # 그냥 라벨값을, 라벨값만큼의 인덱스 위치만 1인 리스트로 바꿔준다 \n",
    "    if one_hot_label:\n",
    "        dataset['train_label'] = _change_ont_hot_label(dataset['train_label'])\n",
    "        dataset['test_label'] = _change_ont_hot_label(dataset['test_label'])    \n",
    "    \n",
    "    # 디폴트는 flatten 되어 있는 것인데 flatten == False 라면\n",
    "    # 다시 reshape 해주는 것이다. 1*28*28로 \n",
    "    if not flatten:\n",
    "         for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
    "\n",
    "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    init_mnist()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
